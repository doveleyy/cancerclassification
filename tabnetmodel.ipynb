{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Classification with TabNet\n",
    "\n",
    "This notebook implements a TabNet deep learning model for cancer type classification. TabNet is a deep learning architecture designed specifically for tabular data, using sequential attention to choose which features to reason from at each decision step.\n",
    "\n",
    "## Overview\n",
    "1. Data loading and preprocessing\n",
    "2. Handling class imbalance with SMOTE\n",
    "3. Model training and evaluation\n",
    "4. Performance analysis with various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "We start by loading the cancer classification dataset and preparing it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "file_path = \"cancer_classification_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "cancer_counts = df['cancer_type'].value_counts()\n",
    "sns.barplot(x=cancer_counts.index, y=cancer_counts.values)\n",
    "plt.title('Cancer Type Distribution')\n",
    "plt.xlabel('Cancer Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['cancer_type'])\n",
    "y = df['cancer_type']\n",
    "\n",
    "# Encode categorical target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split (Keep test set original)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Handling Class Imbalance with SMOTE\n",
    "\n",
    "We'll use the Synthetic Minority Over-sampling Technique (SMOTE) to address class imbalance in our training data. Note that we're only applying SMOTE to the training set to maintain the integrity of our test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution before SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "for label, count in zip(*np.unique(y_train, return_counts=True)):\n",
    "    print(f\"Class {label_encoder.inverse_transform([label])[0]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE only on the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "for label, count in zip(*np.unique(y_train_resampled, return_counts=True)):\n",
    "    print(f\"Class {label_encoder.inverse_transform([label])[0]}: {count} samples\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train_resampled, X_test = np.array(X_train_resampled), np.array(X_test)\n",
    "y_train_resampled, y_test = np.array(y_train_resampled), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TabNet Model Training\n",
    "\n",
    "Now we'll initialize and train the TabNet classifier on our balanced training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TabNet model\n",
    "tabnet_clf = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='entmax'  # Can be 'sparsemax' or 'entmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training TabNet model...\")\n",
    "tabnet_clf.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    eval_set=[(X_train_resampled, y_train_resampled), (X_test, y_test)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy'],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=64,\n",
    "    virtual_batch_size=64,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tabnet_clf.history['train_accuracy'], label='Train')\n",
    "plt.plot(tabnet_clf.history['valid_accuracy'], label='Valid')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('TabNet Training History')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Let's evaluate the trained TabNet model using various metrics to get a comprehensive understanding of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on original test set\n",
    "y_pred = tabnet_clf.predict(X_test)\n",
    "y_proba = tabnet_clf.predict_proba(X_test)\n",
    "\n",
    "# Basic performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"TabNet Accuracy on Original Test Set: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report on Original Test Set:\\n\", \n",
    "      classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute top-k accuracy\n",
    "def top_k_accuracy(y_true, y_pred_proba, k=2):\n",
    "    top_k = np.argsort(y_pred_proba, axis=1)[:, -k:]  # Get top-k predictions\n",
    "    correct = np.array([y_true[i] in top_k[i] for i in range(len(y_true))])\n",
    "    return np.mean(correct)\n",
    "\n",
    "# Compute top-2 and top-3 accuracy\n",
    "top_2_acc = top_k_accuracy(y_test, y_proba, k=2)\n",
    "top_3_acc = top_k_accuracy(y_test, y_proba, k=3)\n",
    "\n",
    "print(f\"TabNet Top-2 Accuracy: {top_2_acc:.4f}\")\n",
    "print(f\"TabNet Top-3 Accuracy: {top_3_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-cancer-type accuracy\n",
    "print(\"\\nPer-Cancer-Type Accuracy:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    correct = np.sum((y_pred == i) & (y_test == i))  # Correctly classified instances\n",
    "    total = np.sum(y_test == i)  # Total instances of this cancer type\n",
    "    class_accuracy = correct / total if total > 0 else 0  # Avoid division by zero\n",
    "    print(f\"Accuracy for cancer type '{label}': {class_accuracy:.4f} ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Greens', fmt='d',\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for TabNet on Original Test Set\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis of Misclassifications\n",
    "\n",
    "Let's analyze which cancer types are most frequently confused with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common misclassifications\n",
    "print(\"Cancer Types Most Confused with Each Other:\")\n",
    "misclassifications = []\n",
    "for i in range(len(label_encoder.classes_)):\n",
    "    for j in range(len(label_encoder.classes_)):\n",
    "        if i != j and conf_matrix[i, j] > 0:\n",
    "            misclassifications.append({\n",
    "                'true': label_encoder.classes_[i],\n",
    "                'predicted': label_encoder.classes_[j],\n",
    "                'count': conf_matrix[i, j]\n",
    "            })\n",
    "\n",
    "# Sort by count in descending order\n",
    "misclassifications.sort(key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "# Display top misclassifications\n",
    "for item in misclassifications[:10]:  # Show top 10\n",
    "    print(f\"{item['true']} is confused with {item['predicted']} with count {item['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've implemented a TabNet deep learning model for cancer type classification. Here's a summary of what we've accomplished:\n",
    "\n",
    "1. Processed and standardized the cancer classification dataset\n",
    "2. Addressed class imbalance using SMOTE on the training data\n",
    "3. Trained a TabNet model with optimized parameters\n",
    "4. Evaluated the model using multiple metrics including per-cancer-type accuracy\n",
    "5. Analyzed misclassifications to identify commonly confused cancer types\n",
    "\n",
    "Potential next steps:\n",
    "- Hyperparameter tuning to further optimize the TabNet model\n",
    "- Feature selection to identify the most discriminative genes for cancer classification\n",
    "- Ensemble with other models (SVM, XGBoost) to improve overall performance\n",
    "- Investigate specific misclassifications and potential biological reasons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
