{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Classification using XGBoost\n",
    "\n",
    "This notebook demonstrates a machine learning pipeline for cancer type classification using XGBoost. The process includes:\n",
    "- Data loading and preprocessing\n",
    "- Handling class imbalance with SMOTE\n",
    "- Feature selection using Random Forest\n",
    "- Hyperparameter tuning with GridSearchCV\n",
    "- Model evaluation with various metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "    confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "file_path = \"cancer_classification_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns=['cancer_type'])\n",
    "y = df['cancer_type']\n",
    "\n",
    "# Encode categorical target variable\n",
    "print(\"Checking target variable for NaN values...\")\n",
    "print(f\"NaN values in target: {y.isna().sum()}\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Display class distribution\n",
    "class_counts = Counter(y_encoded)\n",
    "print(f\"\\nClass distribution: {class_counts}\")\n",
    "print(f\"Number of classes: {len(class_counts)}\")\n",
    "print(\"\\nClass mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"Class {i}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Original Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(*zip(*Counter(y_encoded).items()))\n",
    "plt.xlabel(\"Class Labels\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Original Class Distribution\")\n",
    "plt.xticks(range(len(label_encoder.classes_)), label_encoder.classes_, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling and SMOTE for Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling before SMOTE\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Address class imbalance using SMOTE\n",
    "print(\"Applying SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_encoded)\n",
    "\n",
    "# Check new class distribution after SMOTE\n",
    "print(f\"\\nNew class distribution after SMOTE: {Counter(y_resampled)}\")\n",
    "\n",
    "# Plot resampled class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(*zip(*Counter(y_resampled).items()))\n",
    "plt.xlabel(\"Class Labels\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.xticks(range(len(label_encoder.classes_)), label_encoder.classes_, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model to get feature importances\n",
    "print(\"Training Random Forest model for feature selection...\")\n",
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                            random_state=42,\n",
    "                            class_weight='balanced')\n",
    "rf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Select top 100 most important features\n",
    "print(\"Selecting top 100 features...\")\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "important_features = pd.DataFrame({'Feature': feature_names,\n",
    "                                   'Importance': feature_importances})\n",
    "important_features = important_features.sort_values(by='Importance',\n",
    "                                                    ascending=False)\n",
    "top_features = important_features.head(100)['Feature'].values\n",
    "\n",
    "# Show top 20 features\n",
    "print(\"\\nTop 20 most important features:\")\n",
    "important_features.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(important_features.head(20)['Feature'], important_features.head(20)['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reduce Dataset to Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset to selected features\n",
    "X_reduced = X[top_features]\n",
    "print(f\"Reduced feature set shape: {X_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "print(\"Performing train-test split...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_encoded,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Option 1: XGBoost Model with Best Parameters (Skip GridCV)\n",
    "\n",
    "Use this cell if you want to skip the time-consuming GridSearchCV process and use the best parameters that were previously determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters found from previous GridSearchCV run\n",
    "best_params = {\n",
    "    'colsample_bytree': 1.0,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost model with best parameters...\")\n",
    "print(f\"Using parameters: {best_params}\")\n",
    "\n",
    "# Create and train model with best parameters\n",
    "best_xgb_model = XGBClassifier(\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    subsample=best_params['subsample'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions on test data...\")\n",
    "y_pred = best_xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Option 2: Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "**Note:** This process can be time-consuming. Run this cell if you want to perform your own hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV for cross-validation\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "print(\"Performing hyperparameter tuning with cross-validation...\")\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5,\n",
    "                           scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "print(\"Training best XGB model...\")\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions on test data...\")\n",
    "y_pred = best_xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the XGBoost model\n",
    "print(f\"Accuracy of XGBoost model: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report for XGBoost:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create a function to calculate top-k accuracy\n",
    "def top_k_accuracy(y_true, y_pred_proba, k=2):\n",
    "    top_k = np.argsort(y_pred_proba, axis=1)[:, -k:]\n",
    "    correct = np.array([y_true[i] in top_k[i] for i in range(len(y_true))])\n",
    "    return np.mean(correct)\n",
    "\n",
    "# Calculate top-2 accuracy\n",
    "y_pred_proba = best_xgb_model.predict_proba(X_test)\n",
    "top_2_accuracy = top_k_accuracy(y_test, y_pred_proba, k=2)\n",
    "print(f\"\\nTop-2 Accuracy: {top_2_accuracy:.4f}\")\n",
    "\n",
    "# Calculate top-3 accuracy\n",
    "top_3_accuracy = top_k_accuracy(y_test, y_pred_proba, k=3)\n",
    "print(f\"Top-3 Accuracy: {top_3_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cancer-Type Specific Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer-type specific accuracy (for each class)\n",
    "print(\"Cancer-type specific accuracy:\")\n",
    "class_accuracies = {}\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    class_indices = np.where(y_test == i)[0]\n",
    "    if len(class_indices) > 0:\n",
    "        class_accuracy = np.mean(y_pred[class_indices] == y_test[class_indices])\n",
    "        class_accuracies[label] = class_accuracy\n",
    "        print(f\"Accuracy for cancer type '{label}': {class_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"No test samples for cancer type '{label}'\")\n",
    "\n",
    "# Visualize class-specific accuracies\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(class_accuracies.keys(), class_accuracies.values())\n",
    "plt.xlabel('Cancer Type')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Class-Specific Accuracies')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels\n",
    "tick_marks = np.arange(len(label_encoder.classes_))\n",
    "plt.xticks(tick_marks, label_encoder.classes_, rotation=90)\n",
    "plt.yticks(tick_marks, label_encoder.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Add text annotations\n",
    "thresh = conf_matrix.max() / 2\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        if conf_matrix[i, j] > 0:\n",
    "            plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Analyze Most Confused Cancer Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which cancer types are most confused with each other\n",
    "print(\"Cancer Types Most Confused with Each Other:\")\n",
    "confusion_pairs = []\n",
    "\n",
    "for i in range(len(label_encoder.classes_)):\n",
    "    for j in range(len(label_encoder.classes_)):\n",
    "        if i != j and conf_matrix[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true_type': label_encoder.classes_[i],\n",
    "                'predicted_type': label_encoder.classes_[j],\n",
    "                'count': conf_matrix[i, j]\n",
    "            })\n",
    "            print(f\"{label_encoder.classes_[i]} is confused with {label_encoder.classes_[j]} with count {conf_matrix[i, j]}\")\n",
    "\n",
    "# Create a DataFrame of confusion pairs and sort by count\n",
    "confusion_df = pd.DataFrame(confusion_pairs)\n",
    "most_confused = confusion_df.sort_values('count', ascending=False).head(10)\n",
    "print(\"\\nTop 10 Most Confused Cancer Type Pairs:\")\n",
    "most_confused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Visualize Most Confused Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top confused pairs\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_confused = most_confused.head(10)\n",
    "pair_labels = [f\"{row['true_type']} â†’ {row['predicted_type']}\" for _, row in top_confused.iterrows()]\n",
    "\n",
    "plt.barh(pair_labels, top_confused['count'])\n",
    "plt.xlabel('Count')\n",
    "plt.title('Top 10 Most Confused Cancer Type Pairs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
